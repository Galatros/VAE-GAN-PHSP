{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO funkcja trenująca powinna aktualizować słowniki w checkpoint.pth przypadku wczytania modelu\n",
    "from data_helper import get_dataloaders_and_standarscaler_photons_from_numpy\n",
    "from train_helper import train_vae\n",
    "from plot_helper import plot_training_loss\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 123\n",
    "NUM_EPOCHS = 1\n",
    "LOGGING_INTERVAL=300\n",
    "\n",
    "# RECONSTRUCTION_TERM_WEIGHT=2.8 \n",
    "# LEARNING_RATE = 0.0005\n",
    "# BATCH_SIZE = 1024\n",
    "#TOTAL_NUM_EPOCHS\n",
    "# SAVE_MODEL_FILE\n",
    "\n",
    "PLOT_FRACTION=0.0125\n",
    "TEST_FRACTION=0.4\n",
    "VALIDATION_FRACTION=0.0\n",
    "NUM_WORKERS=0\n",
    "path='/data1/dose-3d-generative/data/training-data/DISP_0.5_ANGLE_0/NUMPY/a1_10_7.npy'\n",
    "CHECKPOINT_PATH=\"TrainedModels/InfoVAE/30epoch_0203_mmd_checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "VAE_Linear_0203\n"
     ]
    }
   ],
   "source": [
    "loaded_checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "\n",
    "BATCH_SIZE = loaded_checkpoint[\"batch_size\"]\n",
    "RECONSTRUCTION_TERM_WEIGHT = loaded_checkpoint[\"reconstruction_term_weight\"]\n",
    "log_dict_old=loaded_checkpoint[\"log_dict\"]\n",
    "\n",
    "epoch = loaded_checkpoint[\"epoch\"]\n",
    "print(epoch)\n",
    "TOTAL_NUM_EPOCHS=epoch+NUM_EPOCHS\n",
    "model_name=loaded_checkpoint[\"model_name\"]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_FILE=f'TrainedModels/BetaVAE/{TOTAL_NUM_EPOCHS}epoch_0203_mmd_checkpoint.pth'#None gdy nie tworzy się nowego zapisu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "CUDA_DEVICE_NUM=0\n",
    "DEVICE = torch.device(f'cuda:{CUDA_DEVICE_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39936\n",
      "2097152\n",
      "Quadro RTX 8000\n",
      "50959679488\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(device=DEVICE))\n",
    "print(torch.cuda.memory_reserved(device=DEVICE))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getattr(__import__('models_architecture_helper', fromlist=[model_name]), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model()\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(loaded_checkpoint[\"model_state\"])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0, \n",
    "                             weight_decay=1e-5)\n",
    "\n",
    "optimizer.load_state_dict(loaded_checkpoint[\"optim_state\"])\n",
    "\n",
    "#print(optimizer.state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000001, 6)\n"
     ]
    }
   ],
   "source": [
    "#ODCZYTANIE DANYCH Z PLIKU 'photons.npy'\n",
    "photons = np.load(path)\n",
    "X = np.zeros((10000001, 6),dtype=np.float32)\n",
    "np.copyto(X,photons[:,:-1])\n",
    "print(X.shape)\n",
    "\n",
    "# photons = np.load(path)\n",
    "# X = np.zeros(photons.shape,dtype=np.float32)\n",
    "# np.copyto(X,photons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000002\n"
     ]
    }
   ],
   "source": [
    "X_reflection=copy.deepcopy(X)\n",
    "X_reflection[:,2]=-X_reflection[:,2]\n",
    "X_reflection[:,4]=-X_reflection[:,4]\n",
    "\n",
    "X_sum=np.concatenate((X,X_reflection),axis=0)\n",
    "print(len(X_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>dX</th>\n",
       "      <th>dY</th>\n",
       "      <th>dZ</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77526</td>\n",
       "      <td>-0.50856</td>\n",
       "      <td>-4.60704</td>\n",
       "      <td>-0.018979</td>\n",
       "      <td>-0.177872</td>\n",
       "      <td>0.983871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77526</td>\n",
       "      <td>-0.77813</td>\n",
       "      <td>-5.10840</td>\n",
       "      <td>-0.029292</td>\n",
       "      <td>-0.196501</td>\n",
       "      <td>0.980066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45010</td>\n",
       "      <td>-3.74409</td>\n",
       "      <td>-1.33591</td>\n",
       "      <td>-0.145330</td>\n",
       "      <td>-0.051869</td>\n",
       "      <td>0.988023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39630</td>\n",
       "      <td>-2.50916</td>\n",
       "      <td>-3.30103</td>\n",
       "      <td>-0.274393</td>\n",
       "      <td>-0.273584</td>\n",
       "      <td>0.921879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45010</td>\n",
       "      <td>-4.79711</td>\n",
       "      <td>-1.70242</td>\n",
       "      <td>-0.184824</td>\n",
       "      <td>-0.065606</td>\n",
       "      <td>0.980579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X        Y       dX        dY        dZ         E\n",
       "0  0.77526 -0.50856 -4.60704 -0.018979 -0.177872  0.983871\n",
       "1  0.77526 -0.77813 -5.10840 -0.029292 -0.196501  0.980066\n",
       "2  0.45010 -3.74409 -1.33591 -0.145330 -0.051869  0.988023\n",
       "3  0.39630 -2.50916 -3.30103 -0.274393 -0.273584  0.921879\n",
       "4  0.45010 -4.79711 -1.70242 -0.184824 -0.065606  0.980579"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.DataFrame(X_sum, columns = ['X', 'Y', 'dX', 'dY', 'dZ', 'E'])\n",
    "df_data.head()#zawsze warto rzucić okiem na dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50126/2035790614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader, valid_loader, test_loader, stdcs = get_dataloaders_and_standarscaler_photons_from_numpy(tmp_X=X_sum,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_FRACTION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     validation_fraction=VALIDATION_FRACTION)\n",
      "\u001b[0;32m~/Projekty/dose3d-phsp/AE_VAE/Autoencoders_Photons/data_helper.py\u001b[0m in \u001b[0;36mget_dataloaders_and_standarscaler_photons_from_numpy\u001b[0;34m(tmp_X, batch_size, test_fraction, validation_fraction, train_transforms, test_transforms, num_workers)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mstdsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mX_train_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_test_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wykorzystujemy standaryzacje z danych treningowych\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/envs/generative/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/envs/generative/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader, stdcs = get_dataloaders_and_standarscaler_photons_from_numpy(tmp_X=X_sum,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    test_fraction=TEST_FRACTION, \n",
    "    validation_fraction=VALIDATION_FRACTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VAE_Linear()\n",
    "# model.to(DEVICE)\n",
    "\n",
    "#criterion = nn.MSELoss()#FUNKCJA STRATY\n",
    "# optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                              lr=LEARNING_RATE, \n",
    "#                              weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict_new=train_vae(num_epochs=NUM_EPOCHS, device=DEVICE, model=model,optimizer=optimizer,train_loader=train_loader,loss_fn=None, test_loader=test_loader, logging_interval=LOGGING_INTERVAL, reconstruction_term_weight=RECONSTRUCTION_TERM_WEIGHT, save_model_file=SAVE_MODEL_FILE, total_num_of_epochs=TOTAL_NUM_EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict={ key:log_dict_old.get(key,[])+log_dict_new.get(key,[]) for key in set(list(log_dict_old.keys())+list(log_dict_new.keys())) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(log_dict[\"test_combined_loss_per_epoch\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_all=epoch+NUM_EPOCHS\n",
    "plot_training_loss(log_dict['train_reconstruction_loss_per_batch'], epoch_all, custom_label=\" (reconstruction)\")\n",
    "plot_training_loss(log_dict['train_kl_loss_per_batch'], epoch_all, custom_label=\" (KL)\")\n",
    "plot_training_loss(log_dict['train_combined_loss_per_batch'], epoch_all, custom_label=\" (combined)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(log_dict['train_combined_loss_per_epoch'])), (log_dict['train_combined_loss_per_epoch']), label='Train Epoch Loss')\n",
    "plt.plot(range(len(log_dict['test_combined_loss_per_epoch'])), (log_dict['test_combined_loss_per_epoch']), label='Test Epoch Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "#plt.ylim(0.15,0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_data.to_numpy(dtype=np.float32)\n",
    "orginal=copy.deepcopy(tmp)\n",
    "tmp=stdcs.transform(tmp)\n",
    "tmp=torch.from_numpy(tmp)\n",
    "#print(tmp)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result_encoded_features, z_mean, z_log_var, result_decoded_features =model(tmp.to(device=DEVICE))\n",
    "result=result_decoded_features.cpu().detach().numpy()\n",
    "result=stdcs.inverse_transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.set_size_inches(16,8)\n",
    "bins=100\n",
    "axs[0, 0].hist(orginal[:,0],bins=bins, label ='orginal',alpha=0.5, density=True)\n",
    "axs[0, 0].hist(result[:,0],bins=bins, label ='decoded', alpha=0.5, density=True)\n",
    "axs[0, 0].set_title('X')\n",
    "axs[0, 1].hist(orginal[:,1],bins=bins, label ='orginal',alpha=0.5, density=True)\n",
    "axs[0, 1].hist(result[:,1],bins=bins, label ='decoded', alpha=0.5, density=True)\n",
    "axs[0, 1].set_title('Y')\n",
    "axs[0, 2].hist(orginal[:,2],bins=bins, label ='orginal',alpha=0.5, density=True)\n",
    "axs[0, 2].hist(result[:,2],bins=bins, label ='decoded', alpha=0.5, density=True)\n",
    "axs[0, 2].set_title('dX')\n",
    "axs[1, 0].hist(orginal[:,3],bins=bins, label ='orginal',alpha=0.5, density=True)\n",
    "axs[1, 0].hist(result[:,3],bins=bins, label ='decoded', alpha=0.5, density=True)\n",
    "axs[1, 0].set_title('dY')\n",
    "axs[1, 1].hist(orginal[:,4],bins=bins, label ='orginal',alpha=0.5, density=True)\n",
    "axs[1, 1].hist(result[:,4],bins=bins, label ='decoded', alpha=0.5, density=True)\n",
    "axs[1, 1].set_title('dZ')\n",
    "axs[1, 2].hist(orginal[:,5],bins=bins, label ='orginal',alpha=0.5, density=True)\n",
    "axs[1, 2].hist(result[:,5],bins=bins, label ='decoded', alpha=0.5, density=True)\n",
    "axs[1, 2].set_title('E')\n",
    "fig.legend()\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     ax.set(xlabel='x-label', ylabel='y-label')\n",
    "\n",
    "# # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = df_data.columns\n",
    "# print(keys)\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.set_size_inches(20, 20)\n",
    "for i, j in enumerate(keys):\n",
    "    mi = np.minimum(orginal[:, i].min(), result[:, i].min())\n",
    "    ma = np.maximum(orginal[:, i].max(), result[:, i].max())\n",
    "    bins = np.linspace(mi, ma, 300)\n",
    "    # print(bins)\n",
    "    axs.flatten()[i].hist(orginal[:, i], bins, alpha=.5)\n",
    "    axs.flatten()[i].hist(result[:, i], bins, alpha=.5)\n",
    "    axs.flatten()[i].set_title(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_df=pd.DataFrame(result,columns=['X', 'Y', 'dX', 'dY', 'dZ', 'E'])\n",
    "orginal_df=df_data.iloc[:,:]\n",
    "\n",
    "\n",
    "concatenated_datasets=pd.concat([orginal_df.assign(dataset_name='orginal'), decoded_df.assign(dataset_name='decoded')],ignore_index=True)\n",
    "concatenated_datasets.shape\n",
    "print(concatenated_datasets.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO trzeba by sprawdzić czy to losowanie działa poprawnie i zwraca próbkę reprezentatywną\n",
    "sample_concatenated=concatenated_datasets.groupby('dataset_name', group_keys=False).apply(lambda x: x.sample(frac=PLOT_FRACTION, random_state=2)) \n",
    "print(sample_concatenated.shape)\n",
    "print(sample_concatenated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(sample_concatenated, hue=\"dataset_name\", kind=\"scatter\", plot_kws=dict(alpha=0.5))\n",
    "#sns.pairplot(concatenated_datasets, hue=\"dataset_name\", kind=\"scatter\", plot_kws=dict(alpha=0.5),corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_orginal=orginal_df.apply(lambda x: x.sample(frac=PLOT_FRACTION, random_state=2)) \n",
    "print(sample_orginal.shape)\n",
    "print(sample_orginal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(sample_orginal, kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decoded=decoded_df.apply(lambda x: x.sample(frac=PLOT_FRACTION, random_state=2)) \n",
    "print(sample_decoded.shape)\n",
    "print(sample_decoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(sample_decoded, kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.PairGrid(concatenated_datasets, hue='dataset_name')\n",
    "# g.map_upper(sns.scatterplot)\n",
    "# #g.map_lower(sns.kdeplot, fill=True)\n",
    "# g.map_diag(sns.histplot, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_2=df_data.iloc[37:38,:]\n",
    "tmp_2=tmp_2.to_numpy(dtype=np.float32)\n",
    "orginal_2=tmp_2\n",
    "tmp_2=stdcs.transform(tmp_2)\n",
    "tmp_2=torch.from_numpy(tmp_2)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result_encoded_features_2, z_mean_2, z_log_var_2, result_decoded_features_2=model(tmp_2.to(device=DEVICE))\n",
    "result_2=result_decoded_features_2.cpu().detach().numpy()\n",
    "result_2=stdcs.inverse_transform(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_2=orginal_2.flatten()\n",
    "result_2=result_2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(np.stack((orginal_2,result_2)), columns=['X', 'Y', 'dX', 'dY', 'dZ', 'E'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features=[]\n",
    "model.eval()\n",
    "for index, feature in enumerate(train_loader):\n",
    "    with torch.no_grad():\n",
    "        tmp_encoded_features, z_mean, z_log_var, decoded =model(feature.to(device=DEVICE))\n",
    "        encoded_features.extend(tmp_encoded_features.cpu().detach().numpy())\n",
    "encoded_features=np.asarray(encoded_features)\n",
    "\n",
    "print(encoded_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRZESTRZEŃ UKRYTA VAE\n",
    "colors = ['r']\n",
    "markers = ['s']\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(projection='3d')\n",
    "for c, m in zip(colors, markers):\n",
    "    ax.scatter(encoded_features[:,0],encoded_features[:,1],encoded_features[:,2],marker=m,c=c)\n",
    "\n",
    "ax.set_xlabel('VAE 1')\n",
    "ax.set_ylabel('VAE 2')\n",
    "ax.set_zlabel('VAE 3')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94e50cba98016e2c68fceb7b9fa13391593fa96fd78bad5a436d2ca9f0548949"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch_wine_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
