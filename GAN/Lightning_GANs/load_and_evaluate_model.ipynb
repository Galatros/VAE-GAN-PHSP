{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from models.GAN import Lit_GAN\n",
    "from models.WGAN import Lit_WGAN\n",
    "from models.WGAN_gp import Lit_WGAN_gp\n",
    "from helpers.PhotonsDataModule import PhotonsDataModule\n",
    "from helpers.plot_helper import get_subplot_adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT_PATH='/home/jakmic/Projekty/dose3d-phsp/GAN/Lightning_GANs/results/WGAN_gp/version_1/checkpoints/last.ckpt'\n",
    "DATA_PATH='/data1/dose-3d-generative/data/training-data/PHSPs_without_VR/Filtered_E5.6_s0.0.npy'\n",
    "BATCH_SIZE=400000\n",
    "NUM_WORKERS=0\n",
    "TEST_FRACTION=0.0\n",
    "VALIDATION_FRACTION = 0.4\n",
    "SHUFFLE_TRAIN=False\n",
    "RANDOM_SEED=123\n",
    "\n",
    "LANTENT_SPACE_DIM=8\n",
    "NUM_SUBPLOT_ROWS, NUM_SUBPLOT_COLUMNS = get_subplot_adjustment(LANTENT_SPACE_DIM)\n",
    "print(NUM_SUBPLOT_ROWS, NUM_SUBPLOT_COLUMNS)\n",
    "\n",
    "KEYS = ['E','X', 'Y', 'dX', 'dY', 'dZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to change model !!!\n",
    "dm=PhotonsDataModule(data_path=DATA_PATH,batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,test_fraction=TEST_FRACTION,validation_fraction=VALIDATION_FRACTION,shuffle_train=SHUFFLE_TRAIN,random_seed=RANDOM_SEED)\n",
    "model=Lit_WGAN_gp.load_from_checkpoint(LOAD_CHECKPOINT_PATH)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_photons=np.empty((0,6))\n",
    "generated=np.empty((0,6))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for photon_batch in dm.val_dataloader():\n",
    "        # Generate noise batch from normal distribution\n",
    "        noise_batch=torch.randn(size=(photon_batch.size(0),LANTENT_SPACE_DIM))\n",
    "\n",
    "        # Generate photon batch\n",
    "        generated_batch = model(noise_batch)\n",
    "\n",
    "        photon_batch=photon_batch.cpu().detach().numpy()\n",
    "        generated_batch=generated_batch.cpu().detach().numpy()\n",
    "        # noise_batch=noise_batch.cpu().detach().numpy()\n",
    "        \n",
    "        # Standarizer inverse transform\n",
    "        photon_batch=dm.stdcs.inverse_transform(photon_batch)\n",
    "        generated_batch=dm.stdcs.inverse_transform(generated_batch)\n",
    "\n",
    "        # Prepare numpy arrays\n",
    "        # noise = np.append(noise, noise_batch, axis=0)\n",
    "        generated = np.append(generated, generated_batch,axis=0)\n",
    "        orginal_photons = np.append(orginal_photons,photon_batch, axis=0)\n",
    "    \n",
    "        print(generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.set_size_inches(20, 14)\n",
    "for i, j in enumerate(KEYS):\n",
    "    mi = np.minimum(orginal_photons[:, i].min(), generated[:, i].min())\n",
    "    ma = np.maximum(orginal_photons[:, i].max(), generated[:, i].max())\n",
    "    if j=='dZ':\n",
    "        mi=0.8\n",
    "    bins = np.linspace(mi, ma, 300)\n",
    "    axs.flatten()[i].hist(orginal_photons[:, i], bins, alpha=.5, label='orginal')\n",
    "    axs.flatten()[i].hist(generated[:, i], bins, alpha=.5, label='generated')\n",
    "    axs.flatten()[i].set_title(j)\n",
    "    axs.flatten()[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.set_size_inches(20, 14)\n",
    "for i, j in enumerate(KEYS):\n",
    "    mi = np.minimum(orginal_photons[:, i].min(), generated[:, i].min())\n",
    "    ma = np.maximum(orginal_photons[:, i].max(), generated[:, i].max())\n",
    "    if j=='E':\n",
    "        mi=-0.1\n",
    "    if j=='dZ':\n",
    "        mi=0.8\n",
    "    bins = np.linspace(mi, ma, 300)\n",
    "    axs.flatten()[i].hist(orginal_photons[:, i], bins, alpha=.5, label='orginal', stacked = True, density = True, log = True)\n",
    "    axs.flatten()[i].hist(generated[:, i], bins, alpha=.5, label='generated', stacked = True, density = True, log = True)\n",
    "    axs.flatten()[i].set_title(j)\n",
    "    axs.flatten()[i].legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b49ffdf1bf063af7ff26dd1ef9dd65469985430119a126229acbeb0592f571b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('generative')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
